{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2a66dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af8a765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load reqiured package :\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "import cx_Oracle\n",
    "import datetime\n",
    "import csv\n",
    "import time\n",
    "import sys\n",
    "import os \n",
    "#----------------------------------------------------------------------\n",
    "#----------------------------------------------------------------------\n",
    "# Access on Orcale DataBase :\n",
    "def dbConnect():\n",
    "    '''\n",
    "    creates a standalone connection with the database\n",
    "    parameters:\n",
    "        none\n",
    "        \n",
    "    return: \n",
    "       con: cx_oracle connection\n",
    "    '''\n",
    "    \n",
    "    con = cx_Oracle.connect('STOCK/P3rXdM5HbSgQRmCS@10.1.20.41:1521/STOCK')\n",
    "    print (con.version)\n",
    "    return con\n",
    "#----------------------------------------------------------------------\n",
    "#----------------------------------------------------------------------\n",
    "HistTicker  = input(\"Enter Historical Name of Ticker :: \")\n",
    "NewTicker   = input(\"Enter New Name of Ticker :: \")\n",
    "foldataname = input(\"Enter The Folder Name to store data  :: \")\n",
    "MergeCSVFileNAme = input(\"Enter The Csv File Name to store data  :: \")\n",
    "print(\"Please double check Names of that Tickers again ::\")\n",
    "print(\"=================================Set input param first time done done=================================\")\n",
    "print(\"==================================================================================\")\n",
    "Confirmation  = input(\"Enter YES if u Confirmed or NO to reset inputs again:: \")\n",
    "if(Confirmation == \"YES\"):\n",
    "    print(\"=================================second Confirmation without resting case done=================================\")\n",
    "    print(\"==================================================================================\")\n",
    "    pass\n",
    "else :\n",
    "    print(\"Please reset that inputs again\")\n",
    "    HistTicker  = input(\"Enter Historical Name of Ticker :: \")\n",
    "    NewTicker   = input(\"Enter New Name of Ticker :: \")\n",
    "    foldataname = input(\"Enter The Folder Name to store data  :: \")\n",
    "    MergeCSVFileNAme = input(\"Enter The Csv File Name to store data  :: \")\n",
    "    print(\"=================================second Confirmation and reset inputs case done=================================\")\n",
    "    print(\"==================================================================================\")\n",
    "    \n",
    "#----------------------------------------------------------------------\n",
    "#----------------------------------------------------------------------\n",
    "# Read all data of FILL_OHLCV Table\n",
    "con = cx_Oracle.connect('STOCK/P3rXdM5HbSgQRmCS@10.1.20.41:1521/STOCK')\n",
    "sql='SELECT * FROM FILL_OHLCV' \n",
    "cursor = con.cursor()   \n",
    "cursor.execute(sql)\n",
    "#con.commit()\n",
    "FILL_OHLCV_data = pd.read_sql(sql, con)\n",
    "FILL_OHLCV_data.to_csv(\"FILL_OHLCV_data.csv\")\n",
    "FILL_OHLCV_dataFile = pd.read_csv(\"FILL_OHLCV_data.csv\")\n",
    "FILL_OHLCV_dataFile\n",
    "#----------------------------------------------------------------------\n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "FILL_OHLCV_dataFile[FILL_OHLCV_dataFile[\"TICKER\"] == HistTicker].to_csv(f\"{HistTicker}HistTickerdata.csv\")\n",
    "FILL_OHLCV_dataFile[FILL_OHLCV_dataFile[\"TICKER\"] == NewTicker].to_csv(f\"{NewTicker}NewTickerdata.csv\")\n",
    "print(\"=================================Save data Tickers on csv files done=================================\")\n",
    "print(\"==================================================================================\")\n",
    "HistTickerdf = pd.read_csv(f\"{HistTicker}HistTickerdata.csv\")\n",
    "NewTickerdf = pd.read_csv(f\"{NewTicker}NewTickerdata.csv\")\n",
    "HistTickersdfcols = HistTickerdf.columns\n",
    "NewTickerdfcols = NewTickerdf.columns\n",
    "print(f\"Columns of Hist Ticker ({HistTicker})\\n=========\\n{HistTickersdfcols}==========================================\" )\n",
    "print(f\"Columns of New Ticker ({NewTicker})\\n============\\n{NewTickerdfcols}===========================================\" )\n",
    "print(f\"Columns of Hist Ticker df of  ({HistTicker})\\n============\\n{NewTickerdf}===========================================\" )\n",
    "print(f\"Columns of New  Ticker df of  ({NewTicker} )\\n============\\n{NewTickerdf}===========================================\" )\n",
    "HistTickerdf[\"TICKER\"] = HistTickerdf[\"TICKER\"].apply(lambda x : f\"{NewTicker}\" if x == f\"{HistTicker}\" else f\"{NewTicker}\")\n",
    "print(HistTickerdf)\n",
    "print(f\"=====================Renamed Hist Ticker({HistTicker}) To Ticker({NewTicker})========================\")\n",
    "print(\"==================================================================================\")\n",
    "os.mkdir(f\"{foldataname}\")\n",
    "print(f\"====================={foldataname} Folder Created=========================\")\n",
    "print(\"==================================================================================\")\n",
    "for Histcol in HistTickersdfcols :\n",
    "    if(Histcol== 'TICKER' or Histcol== 'OPEN' or Histcol== 'HIGH' or Histcol== 'LOW' or Histcol== 'CLOSE' or Histcol== 'VOLUME' or Histcol== 'BARTIMESTAMP' or Histcol== 'ASSET' or Histcol== 'VWAP') :\n",
    "        print(f\"We didn't delet that column :: {Histcol}\")\n",
    "        pass\n",
    "    else :\n",
    "        print(f\"We deleted that column :: {Histcol}\")\n",
    "        HistTickerdf = HistTickerdf.drop([Histcol], axis=1)\n",
    "HistTickerdf.to_csv(f\"{foldataname}/0({HistTicker})HistTickerdata.csv\" , index=False)\n",
    "print(\"Handle Historical Ticker data file  Done\")\n",
    "print(\"=============================================================\")\n",
    "for Newcol in NewTickerdfcols :\n",
    "    if(Newcol== 'TICKER' or Newcol=='OPEN' or Newcol=='HIGH' or Newcol=='LOW' or Newcol=='CLOSE' or Newcol=='VOLUME' or Newcol=='BARTIMESTAMP' or Newcol=='ASSET' or Newcol=='VWAP') :\n",
    "        print(f\"We didn't delet that columns :: {Newcol}\")\n",
    "        pass\n",
    "    else :\n",
    "        print(f\"We deleted that columns :: {Newcol}\")\n",
    "        NewTickerdf = NewTickerdf.drop([Newcol], axis=1)\n",
    "NewTickerdf.to_csv(f\"{foldataname}/1({NewTicker})NewTickerdata.csv\" , index=False)\n",
    "print(\"Handle New Ticker data file  Done\")\n",
    "print(\"=============================================================\")\n",
    "print(\"=============================================================\")\n",
    "print(\"=============================================================\")\n",
    "LastHandleHistTickerdf=pd.read_csv(f\"{foldataname}/0({HistTicker})HistTickerdata.csv\" )\n",
    "print(LastHandleHistTickerdf)\n",
    "print(\"=============================================================\")\n",
    "print(\"=============================================================\")\n",
    "LastHandleNewTickerdf=pd.read_csv(f\"{foldataname}/1({NewTicker})NewTickerdata.csv\" )\n",
    "print(LastHandleNewTickerdf)\n",
    "print(\"=============================================================\")\n",
    "print(\"=============================================================\")\n",
    "path = os.path.abspath('') \n",
    "path = path+\"\\\\\"+foldataname\n",
    "print(f\"The Path Dirction :: {path}\\n----------------\\n\\nThe Content Path\\n\")\n",
    "print(\"=======================Path found done===============================\")\n",
    "print(\"==========================================================================\")\n",
    "#----------------------------------------------------------------------\n",
    "#----------------------------------------------------------------------\n",
    "df = pd.DataFrame()\n",
    "files = os.listdir(path)\n",
    "for file in files:\n",
    "    if file.endswith('.csv'):\n",
    "        print(file)\n",
    "        df = df.append(pd.read_csv(f\"{path}\\\\{file}\"), ignore_index=True) \n",
    "df.head() \n",
    "df.to_csv(f'{path}\\\\{MergeCSVFileNAme}.csv' , index = False)\n",
    "print(\"=======================Read 2 CSV Filies and Merged done============================\")\n",
    "print(\"==========================================================================\")\n",
    "tbIns = pd.read_csv(f'{path}\\\\{MergeCSVFileNAme}.csv' )\n",
    "# casting DataTime Tybe\n",
    "tbIns['BARTIMESTAMP'] = pd.to_datetime(tbIns['BARTIMESTAMP'],  errors='coerce')\n",
    "# Set DateTime as Index of DataFrame\n",
    "tbIns.set_index(\"BARTIMESTAMP\" , inplace=True)\n",
    "tbIns.sort_index(ascending = True, inplace=True)\n",
    "print(\"======================Sorting Data of File done============================\")\n",
    "print(\"==========================================================================\")\n",
    "tbIns\n",
    "#----------------------------------------------------------------------\n",
    "#----------------------------------------------------------------------\n",
    "Reconfirmation = input(\"\"\"Please double check all process before insert any records  before updates\n",
    "                           If u are confirmed all processes set Yes if didn't confirm set NO:: \"\"\")\n",
    "if(Reconfirmation == \"YES\") :\n",
    "    print(\"Last Confirmation done thanks allots Ahmad Elsayed Ibrahim\")\n",
    "    con=dbConnect()\n",
    "    cur = con.cursor()\n",
    "    lines=[]\n",
    "    for index,row in tbIns.iterrows():\n",
    "        try:\n",
    "            line=[0,1,2,3,4,5,6,7,8]\n",
    "            line[0]=row[\"TICKER\"]\n",
    "            #line[0]=\"ABG\"\n",
    "            line[1]=row['OPEN']\n",
    "            line[2]=row['HIGH']\n",
    "            line[3]=row['LOW']\n",
    "            line[4]=row['CLOSE']\n",
    "            line[5]=row['VOLUME']\n",
    "            line[6]=index.to_pydatetime()\n",
    "            line[7]=1\n",
    "            line[8]=row['VWAP']\n",
    "            #print(index.to_pydatetime())\n",
    "            lines.append(line)\n",
    "\n",
    "            #print(lines)\n",
    "            print(line)\n",
    "            cur.execute(\"insert into FILL_OHLCV(TICKER,OPEN,HIGH,LOW,CLOSE,VOLUME,BARTIMESTAMP,ASSET,VWAP) values (:TICKER, :OPEN,:HIGH,:LOW,:CLOSE,:VOLUME,:BARTIMESTAMP,:1,:2)\",line)\n",
    "            con.commit()\n",
    "        except Exception as e:\n",
    "\n",
    "            print(str(e))\n",
    "            print(line)\n",
    "else :\n",
    "    print(\"Please double check process before any updates\")\n",
    "    break\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bbf379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cd66cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b3e001",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a49c84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4437e3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Load reqiured package :\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "import cx_Oracle\n",
    "import datetime\n",
    "import csv\n",
    "import time\n",
    "import sys\n",
    "import os \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96a29fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Access on Orcale DataBase :\n",
    "def dbConnect():\n",
    "    '''\n",
    "    creates a standalone connection with the database\n",
    "    parameters:\n",
    "        none\n",
    "        \n",
    "    return: \n",
    "       con: cx_oracle connection\n",
    "    '''\n",
    "    \n",
    "    con = cx_Oracle.connect('STOCK/P3rXdM5HbSgQRmCS@10.1.20.41:1521/STOCK')\n",
    "    print (con.version)\n",
    "    return con\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "02f48ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Read all data of FILL_OHLCV Table\\ncon = cx_Oracle.connect(\\'STOCK/P3rXdM5HbSgQRmCS@10.1.20.41:1521/STOCK\\')\\nsql=\\'SELECT * FROM FILL_OHLCV\\' \\ncursor = con.cursor()   \\ncursor.execute(sql)\\n#con.commit()\\nFILL_OHLCV_data = pd.read_sql(sql, con)\\nFILL_OHLCV_data.to_csv(\"FILL_OHLCV_data.csv\")\\nFILL_OHLCV_dataFile = pd.read_csv(\"FILL_OHLCV_data.csv\")\\nFILL_OHLCV_dataFile\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Read all data of FILL_OHLCV Table\n",
    "con = cx_Oracle.connect('STOCK/P3rXdM5HbSgQRmCS@10.1.20.41:1521/STOCK')\n",
    "sql='SELECT * FROM FILL_OHLCV' \n",
    "cursor = con.cursor()   \n",
    "cursor.execute(sql)\n",
    "#con.commit()\n",
    "FILL_OHLCV_data = pd.read_sql(sql, con)\n",
    "FILL_OHLCV_data.to_csv(\"FILL_OHLCV_data.csv\")\n",
    "FILL_OHLCV_dataFile = pd.read_csv(\"FILL_OHLCV_data.csv\")\n",
    "FILL_OHLCV_dataFile\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c4011b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Historical Name of Ticker :: AUTO\n",
      "Enter New Name of Ticker :: GBCO\n",
      "Enter The Folder Name to store data  :: AHMed\n",
      "Enter The Csv File Name to store data  :: AUTOGBCO\n",
      "Please double check Names of that Tickers again ::\n",
      "=================================Set input param first time done done=================================\n",
      "==================================================================================\n",
      "Enter YES if u Confirmed or NO to reset inputs again:: YES\n",
      "=================================second Confirmation without resting case done=================================\n",
      "==================================================================================\n",
      "=================================Save data Tickers on csv files done=================================\n",
      "==================================================================================\n",
      "Columns of Hist Ticker (AUTO)\n",
      "=========\n",
      "Index(['Unnamed: 0', 'Unnamed: 0.1', 'TICKER', 'OPEN', 'HIGH', 'LOW', 'CLOSE',\n",
      "       'VOLUME', 'BARTIMESTAMP', 'ASSET', 'VWAP'],\n",
      "      dtype='object')==========================================\n",
      "Columns of New Ticker (GBCO)\n",
      "============\n",
      "Index(['Unnamed: 0', 'Unnamed: 0.1', 'TICKER', 'OPEN', 'HIGH', 'LOW', 'CLOSE',\n",
      "       'VOLUME', 'BARTIMESTAMP', 'ASSET', 'VWAP'],\n",
      "      dtype='object')===========================================\n",
      "Columns of Hist Ticker df of  (AUTO)\n",
      "============\n",
      "     Unnamed: 0  Unnamed: 0.1 TICKER  OPEN  HIGH   LOW  CLOSE  VOLUME  \\\n",
      "0      17735998      17735998   GBCO  5.44  5.45  5.42   5.43   91923   \n",
      "1      17736061      17736061   GBCO  5.48  5.50  5.48   5.48   21226   \n",
      "2      17736724      17736724   GBCO  6.11  6.14  6.08   6.13  774750   \n",
      "3      17736818      17736818   GBCO  6.12  6.14  6.11   6.11  111098   \n",
      "4      17745042      17745042   GBCO  5.48  5.48  5.45   5.45    9890   \n",
      "..          ...           ...    ...   ...   ...   ...    ...     ...   \n",
      "488    18669272      18669272   GBCO  5.58  5.59  5.58   5.59   25710   \n",
      "489    18669523      18669523   GBCO  5.50  5.50  5.48   5.50   75475   \n",
      "490    18669925      18669925   GBCO  5.63  5.64  5.63   5.63   21412   \n",
      "491    18671382      18671382   GBCO  5.61  5.64  5.61   5.64     283   \n",
      "492    18671527      18671527   GBCO  5.49  5.50  5.48   5.48   11957   \n",
      "\n",
      "            BARTIMESTAMP  ASSET      VWAP  \n",
      "0    2023-06-06 13:20:00    1.0  5.444782  \n",
      "1    2023-06-07 12:05:00    1.0  5.472861  \n",
      "2    2023-06-13 13:05:00    1.0  6.037174  \n",
      "3    2023-06-13 13:20:00    1.0  6.043530  \n",
      "4    2023-06-07 12:25:00    1.0  5.474481  \n",
      "..                   ...    ...       ...  \n",
      "488  2023-06-01 12:00:00    1.0  5.603240  \n",
      "489  2023-06-05 13:25:00    1.0  5.529863  \n",
      "490  2023-06-04 10:40:00    1.0  5.632742  \n",
      "491  2023-06-01 13:00:00    1.0  5.604718  \n",
      "492  2023-06-05 13:30:00    1.0  5.527391  \n",
      "\n",
      "[493 rows x 11 columns]===========================================\n",
      "Columns of New  Ticker df of  (GBCO )\n",
      "============\n",
      "     Unnamed: 0  Unnamed: 0.1 TICKER  OPEN  HIGH   LOW  CLOSE  VOLUME  \\\n",
      "0      17735998      17735998   GBCO  5.44  5.45  5.42   5.43   91923   \n",
      "1      17736061      17736061   GBCO  5.48  5.50  5.48   5.48   21226   \n",
      "2      17736724      17736724   GBCO  6.11  6.14  6.08   6.13  774750   \n",
      "3      17736818      17736818   GBCO  6.12  6.14  6.11   6.11  111098   \n",
      "4      17745042      17745042   GBCO  5.48  5.48  5.45   5.45    9890   \n",
      "..          ...           ...    ...   ...   ...   ...    ...     ...   \n",
      "488    18669272      18669272   GBCO  5.58  5.59  5.58   5.59   25710   \n",
      "489    18669523      18669523   GBCO  5.50  5.50  5.48   5.50   75475   \n",
      "490    18669925      18669925   GBCO  5.63  5.64  5.63   5.63   21412   \n",
      "491    18671382      18671382   GBCO  5.61  5.64  5.61   5.64     283   \n",
      "492    18671527      18671527   GBCO  5.49  5.50  5.48   5.48   11957   \n",
      "\n",
      "            BARTIMESTAMP  ASSET      VWAP  \n",
      "0    2023-06-06 13:20:00    1.0  5.444782  \n",
      "1    2023-06-07 12:05:00    1.0  5.472861  \n",
      "2    2023-06-13 13:05:00    1.0  6.037174  \n",
      "3    2023-06-13 13:20:00    1.0  6.043530  \n",
      "4    2023-06-07 12:25:00    1.0  5.474481  \n",
      "..                   ...    ...       ...  \n",
      "488  2023-06-01 12:00:00    1.0  5.603240  \n",
      "489  2023-06-05 13:25:00    1.0  5.529863  \n",
      "490  2023-06-04 10:40:00    1.0  5.632742  \n",
      "491  2023-06-01 13:00:00    1.0  5.604718  \n",
      "492  2023-06-05 13:30:00    1.0  5.527391  \n",
      "\n",
      "[493 rows x 11 columns]===========================================\n",
      "        Unnamed: 0  Unnamed: 0.1 TICKER  OPEN  HIGH   LOW  CLOSE  VOLUME  \\\n",
      "0             9079          9079   GBCO  4.20  4.20  4.16   4.16     500   \n",
      "1             9080          9080   GBCO  4.16  4.16  4.16   4.16    4900   \n",
      "2             9081          9081   GBCO  4.10  4.10  4.10   4.10    4500   \n",
      "3             9082          9082   GBCO  4.10  4.10  4.10   4.10     500   \n",
      "4             9083          9083   GBCO  4.10  4.10  4.09   4.09   30000   \n",
      "...            ...           ...    ...   ...   ...   ...    ...     ...   \n",
      "103097    18670354      18670354   GBCO  4.85  4.85  4.82   4.83  101809   \n",
      "103098    18670640      18670640   GBCO  6.13  6.15  6.13   6.14   90706   \n",
      "103099    18670725      18670725   GBCO  5.90  5.90  5.84   5.85  378066   \n",
      "103100    18670820      18670820   GBCO  5.85  5.85  5.82   5.83  174323   \n",
      "103101    18671632      18671632   GBCO  4.89  4.89  4.87   4.88   25923   \n",
      "\n",
      "               BARTIMESTAMP  ASSET      VWAP  \n",
      "0       2019-05-14 13:00:00    1.0  4.060000  \n",
      "1       2019-05-15 11:35:00    1.0  4.060000  \n",
      "2       2019-05-15 12:30:00    1.0  4.090000  \n",
      "3       2019-05-15 12:35:00    1.0  4.070000  \n",
      "4       2019-05-15 12:40:00    1.0  4.060000  \n",
      "...                     ...    ...       ...  \n",
      "103097  2023-03-27 11:15:00    1.0  4.833837  \n",
      "103098  2023-05-01 10:00:00    1.0  6.130000  \n",
      "103099  2023-05-02 11:25:00    1.0  5.901383  \n",
      "103100  2023-05-02 11:30:00    1.0  5.894488  \n",
      "103101  2023-02-02 10:55:00    1.0  4.947249  \n",
      "\n",
      "[103102 rows x 11 columns]\n",
      "=====================Renamed Hist Ticker(AUTO) To Ticker(GBCO)========================\n",
      "==================================================================================\n",
      "=====================AHMed Folder Created=========================\n",
      "==================================================================================\n",
      "We deleted that column :: Unnamed: 0\n",
      "We deleted that column :: Unnamed: 0.1\n",
      "We didn't delet that column :: TICKER\n",
      "We didn't delet that column :: OPEN\n",
      "We didn't delet that column :: HIGH\n",
      "We didn't delet that column :: LOW\n",
      "We didn't delet that column :: CLOSE\n",
      "We didn't delet that column :: VOLUME\n",
      "We didn't delet that column :: BARTIMESTAMP\n",
      "We didn't delet that column :: ASSET\n",
      "We didn't delet that column :: VWAP\n",
      "Handle Historical Ticker data file  Done\n",
      "=============================================================\n",
      "We deleted that columns :: Unnamed: 0\n",
      "We deleted that columns :: Unnamed: 0.1\n",
      "We didn't delet that columns :: TICKER\n",
      "We didn't delet that columns :: OPEN\n",
      "We didn't delet that columns :: HIGH\n",
      "We didn't delet that columns :: LOW\n",
      "We didn't delet that columns :: CLOSE\n",
      "We didn't delet that columns :: VOLUME\n",
      "We didn't delet that columns :: BARTIMESTAMP\n",
      "We didn't delet that columns :: ASSET\n",
      "We didn't delet that columns :: VWAP\n",
      "Handle New Ticker data file  Done\n",
      "=============================================================\n",
      "=============================================================\n",
      "=============================================================\n",
      "       TICKER  OPEN  HIGH   LOW  CLOSE  VOLUME         BARTIMESTAMP  ASSET  \\\n",
      "0        GBCO  4.20  4.20  4.16   4.16     500  2019-05-14 13:00:00    1.0   \n",
      "1        GBCO  4.16  4.16  4.16   4.16    4900  2019-05-15 11:35:00    1.0   \n",
      "2        GBCO  4.10  4.10  4.10   4.10    4500  2019-05-15 12:30:00    1.0   \n",
      "3        GBCO  4.10  4.10  4.10   4.10     500  2019-05-15 12:35:00    1.0   \n",
      "4        GBCO  4.10  4.10  4.09   4.09   30000  2019-05-15 12:40:00    1.0   \n",
      "...       ...   ...   ...   ...    ...     ...                  ...    ...   \n",
      "103097   GBCO  4.85  4.85  4.82   4.83  101809  2023-03-27 11:15:00    1.0   \n",
      "103098   GBCO  6.13  6.15  6.13   6.14   90706  2023-05-01 10:00:00    1.0   \n",
      "103099   GBCO  5.90  5.90  5.84   5.85  378066  2023-05-02 11:25:00    1.0   \n",
      "103100   GBCO  5.85  5.85  5.82   5.83  174323  2023-05-02 11:30:00    1.0   \n",
      "103101   GBCO  4.89  4.89  4.87   4.88   25923  2023-02-02 10:55:00    1.0   \n",
      "\n",
      "            VWAP  \n",
      "0       4.060000  \n",
      "1       4.060000  \n",
      "2       4.090000  \n",
      "3       4.070000  \n",
      "4       4.060000  \n",
      "...          ...  \n",
      "103097  4.833837  \n",
      "103098  6.130000  \n",
      "103099  5.901383  \n",
      "103100  5.894488  \n",
      "103101  4.947249  \n",
      "\n",
      "[103102 rows x 9 columns]\n",
      "=============================================================\n",
      "=============================================================\n",
      "    TICKER  OPEN  HIGH   LOW  CLOSE  VOLUME         BARTIMESTAMP  ASSET  \\\n",
      "0     GBCO  5.44  5.45  5.42   5.43   91923  2023-06-06 13:20:00    1.0   \n",
      "1     GBCO  5.48  5.50  5.48   5.48   21226  2023-06-07 12:05:00    1.0   \n",
      "2     GBCO  6.11  6.14  6.08   6.13  774750  2023-06-13 13:05:00    1.0   \n",
      "3     GBCO  6.12  6.14  6.11   6.11  111098  2023-06-13 13:20:00    1.0   \n",
      "4     GBCO  5.48  5.48  5.45   5.45    9890  2023-06-07 12:25:00    1.0   \n",
      "..     ...   ...   ...   ...    ...     ...                  ...    ...   \n",
      "488   GBCO  5.58  5.59  5.58   5.59   25710  2023-06-01 12:00:00    1.0   \n",
      "489   GBCO  5.50  5.50  5.48   5.50   75475  2023-06-05 13:25:00    1.0   \n",
      "490   GBCO  5.63  5.64  5.63   5.63   21412  2023-06-04 10:40:00    1.0   \n",
      "491   GBCO  5.61  5.64  5.61   5.64     283  2023-06-01 13:00:00    1.0   \n",
      "492   GBCO  5.49  5.50  5.48   5.48   11957  2023-06-05 13:30:00    1.0   \n",
      "\n",
      "         VWAP  \n",
      "0    5.444782  \n",
      "1    5.472861  \n",
      "2    6.037174  \n",
      "3    6.043530  \n",
      "4    5.474481  \n",
      "..        ...  \n",
      "488  5.603240  \n",
      "489  5.529863  \n",
      "490  5.632742  \n",
      "491  5.604718  \n",
      "492  5.527391  \n",
      "\n",
      "[493 rows x 9 columns]\n",
      "=============================================================\n",
      "=============================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Load reqiured package :\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "import cx_Oracle\n",
    "import datetime\n",
    "import csv\n",
    "import time\n",
    "import sys\n",
    "import os \n",
    "#----------------------------------------------------------------------\n",
    "#----------------------------------------------------------------------\n",
    "# Access on Orcale DataBase :\n",
    "def dbConnect():\n",
    "    '''\n",
    "    creates a standalone connection with the database\n",
    "    parameters:\n",
    "        none\n",
    "        \n",
    "    return: \n",
    "       con: cx_oracle connection\n",
    "    '''\n",
    "    \n",
    "    con = cx_Oracle.connect('STOCK/P3rXdM5HbSgQRmCS@10.1.20.41:1521/STOCK')\n",
    "    print (con.version)\n",
    "    return con\n",
    "#----------------------------------------------------------------------\n",
    "#----------------------------------------------------------------------\n",
    "HistTicker  = input(\"Enter Historical Name of Ticker :: \")\n",
    "NewTicker   = input(\"Enter New Name of Ticker :: \")\n",
    "foldataname = input(\"Enter The Folder Name to store data  :: \")\n",
    "MergeCSVFileNAme = input(\"Enter The Csv File Name to store data  :: \")\n",
    "print(\"Please double check Names of that Tickers again ::\")\n",
    "print(\"=================================Set input param first time done done=================================\")\n",
    "print(\"==================================================================================\")\n",
    "Confirmation  = input(\"Enter YES if u Confirmed or NO to reset inputs again:: \")\n",
    "if(Confirmation == \"YES\"):\n",
    "    print(\"=================================second Confirmation without resting case done=================================\")\n",
    "    print(\"==================================================================================\")\n",
    "    pass\n",
    "else :\n",
    "    print(\"Please reset that inputs again\")\n",
    "    HistTicker  = input(\"Enter Historical Name of Ticker :: \")\n",
    "    NewTicker   = input(\"Enter New Name of Ticker :: \")\n",
    "    foldataname = input(\"Enter The Folder Name to store data  :: \")\n",
    "    MergeCSVFileNAme = input(\"Enter The Csv File Name to store data  :: \")\n",
    "    print(\"=================================second Confirmation and reset inputs case done=================================\")\n",
    "    print(\"==================================================================================\")\n",
    "    \n",
    "#----------------------------------------------------------------------\n",
    "#----------------------------------------------------------------------\n",
    "# Read all data of FILL_OHLCV Table\n",
    "con = cx_Oracle.connect('STOCK/P3rXdM5HbSgQRmCS@10.1.20.41:1521/STOCK')\n",
    "sql='SELECT * FROM FILL_OHLCV' \n",
    "cursor = con.cursor()   \n",
    "cursor.execute(sql)\n",
    "#con.commit()\n",
    "FILL_OHLCV_data = pd.read_sql(sql, con)\n",
    "FILL_OHLCV_data.to_csv(\"FILL_OHLCV_data.csv\")\n",
    "FILL_OHLCV_dataFile = pd.read_csv(\"FILL_OHLCV_data.csv\")\n",
    "FILL_OHLCV_dataFile\n",
    "#----------------------------------------------------------------------\n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "FILL_OHLCV_dataFile[FILL_OHLCV_dataFile[\"TICKER\"] == HistTicker].to_csv(f\"{HistTicker}HistTickerdata.csv\")\n",
    "FILL_OHLCV_dataFile[FILL_OHLCV_dataFile[\"TICKER\"] == NewTicker].to_csv(f\"{NewTicker}NewTickerdata.csv\")\n",
    "print(\"=================================Save data Tickers on csv files done=================================\")\n",
    "print(\"==================================================================================\")\n",
    "HistTickerdf = pd.read_csv(f\"{HistTicker}HistTickerdata.csv\")\n",
    "NewTickerdf = pd.read_csv(f\"{NewTicker}NewTickerdata.csv\")\n",
    "HistTickersdfcols = HistTickerdf.columns\n",
    "NewTickerdfcols = NewTickerdf.columns\n",
    "print(f\"Columns of Hist Ticker ({HistTicker})\\n=========\\n{HistTickersdfcols}==========================================\" )\n",
    "print(f\"Columns of New Ticker ({NewTicker})\\n============\\n{NewTickerdfcols}===========================================\" )\n",
    "print(f\"Columns of Hist Ticker df of  ({HistTicker})\\n============\\n{NewTickerdf}===========================================\" )\n",
    "print(f\"Columns of New  Ticker df of  ({NewTicker} )\\n============\\n{NewTickerdf}===========================================\" )\n",
    "HistTickerdf[\"TICKER\"] = HistTickerdf[\"TICKER\"].apply(lambda x : f\"{NewTicker}\" if x == f\"{HistTicker}\" else f\"{NewTicker}\")\n",
    "print(HistTickerdf)\n",
    "print(f\"=====================Renamed Hist Ticker({HistTicker}) To Ticker({NewTicker})========================\")\n",
    "print(\"==================================================================================\")\n",
    "os.mkdir(f\"{foldataname}\")\n",
    "print(f\"====================={foldataname} Folder Created=========================\")\n",
    "print(\"==================================================================================\")\n",
    "for Histcol in HistTickersdfcols :\n",
    "    if(Histcol== 'TICKER' or Histcol== 'OPEN' or Histcol== 'HIGH' or Histcol== 'LOW' or Histcol== 'CLOSE' or Histcol== 'VOLUME' or Histcol== 'BARTIMESTAMP' or Histcol== 'ASSET' or Histcol== 'VWAP') :\n",
    "        print(f\"We didn't delet that column :: {Histcol}\")\n",
    "        pass\n",
    "    else :\n",
    "        print(f\"We deleted that column :: {Histcol}\")\n",
    "        HistTickerdf = HistTickerdf.drop([Histcol], axis=1)\n",
    "HistTickerdf.to_csv(f\"{foldataname}/0({HistTicker})HistTickerdata.csv\" , index=False)\n",
    "print(\"Handle Historical Ticker data file  Done\")\n",
    "print(\"=============================================================\")\n",
    "for Newcol in NewTickerdfcols :\n",
    "    if(Newcol== 'TICKER' or Newcol=='OPEN' or Newcol=='HIGH' or Newcol=='LOW' or Newcol=='CLOSE' or Newcol=='VOLUME' or Newcol=='BARTIMESTAMP' or Newcol=='ASSET' or Newcol=='VWAP') :\n",
    "        print(f\"We didn't delet that columns :: {Newcol}\")\n",
    "        pass\n",
    "    else :\n",
    "        print(f\"We deleted that columns :: {Newcol}\")\n",
    "        NewTickerdf = NewTickerdf.drop([Newcol], axis=1)\n",
    "NewTickerdf.to_csv(f\"{foldataname}/1({NewTicker})NewTickerdata.csv\" , index=False)\n",
    "print(\"Handle New Ticker data file  Done\")\n",
    "print(\"=============================================================\")\n",
    "print(\"=============================================================\")\n",
    "print(\"=============================================================\")\n",
    "LastHandleHistTickerdf=pd.read_csv(f\"{foldataname}/0({HistTicker})HistTickerdata.csv\" )\n",
    "print(LastHandleHistTickerdf)\n",
    "print(\"=============================================================\")\n",
    "print(\"=============================================================\")\n",
    "LastHandleNewTickerdf=pd.read_csv(f\"{foldataname}/1({NewTicker})NewTickerdata.csv\" )\n",
    "print(LastHandleNewTickerdf)\n",
    "print(\"=============================================================\")\n",
    "print(\"=============================================================\")\n",
    "path = os.path.abspath('') \n",
    "path = path+\"\\\\\"+foldataname\n",
    "print(f\"The Path Dirction :: {path}\\n----------------\\n\\nThe Content Path\\n\")\n",
    "print(\"=======================Path found done===============================\")\n",
    "print(\"==========================================================================\")\n",
    "#----------------------------------------------------------------------\n",
    "#----------------------------------------------------------------------\n",
    "df = pd.DataFrame()\n",
    "files = os.listdir(path)\n",
    "for file in files:\n",
    "    if file.endswith('.csv'):\n",
    "        print(file)\n",
    "        df = df.append(pd.read_csv(f\"{path}\\\\{file}\"), ignore_index=True) \n",
    "df.head() \n",
    "df.to_csv(f'{path}\\\\{MergeCSVFileNAme}.csv' , index = False)\n",
    "print(\"=======================Read 2 CSV Filies and Merged done============================\")\n",
    "print(\"==========================================================================\")\n",
    "tbIns = pd.read_csv(f'{path}\\\\{MergeCSVFileNAme}.csv' )\n",
    "# casting DataTime Tybe\n",
    "tbIns['BARTIMESTAMP'] = pd.to_datetime(tbIns['BARTIMESTAMP'],  errors='coerce')\n",
    "# Set DateTime as Index of DataFrame\n",
    "tbIns.set_index(\"BARTIMESTAMP\" , inplace=True)\n",
    "tbIns.sort_index(ascending = True, inplace=True)\n",
    "print(\"======================Sorting Data of File done============================\")\n",
    "print(\"==========================================================================\")\n",
    "tbIns\n",
    "#----------------------------------------------------------------------\n",
    "#----------------------------------------------------------------------\n",
    "con=dbConnect()\n",
    "cur = con.cursor()\n",
    "lines=[]\n",
    "for index,row in tbIns.iterrows():\n",
    "    try:\n",
    "        line=[0,1,2,3,4,5,6,7,8]\n",
    "        line[0]=row[\"TICKER\"]\n",
    "        #line[0]=\"ABG\"\n",
    "        line[1]=row['OPEN']\n",
    "        line[2]=row['HIGH']\n",
    "        line[3]=row['LOW']\n",
    "        line[4]=row['CLOSE']\n",
    "        line[5]=row['VOLUME']\n",
    "        line[6]=index.to_pydatetime()\n",
    "        line[7]=1\n",
    "        line[8]=row['VWAP']\n",
    "        #print(index.to_pydatetime())\n",
    "        lines.append(line)\n",
    "\n",
    "        #print(lines)\n",
    "        print(line)\n",
    "        cur.execute(\"insert into FILL_OHLCV(TICKER,OPEN,HIGH,LOW,CLOSE,VOLUME,BARTIMESTAMP,ASSET,VWAP) values (:TICKER, :OPEN,:HIGH,:LOW,:CLOSE,:VOLUME,:BARTIMESTAMP,:1,:2)\",line)\n",
    "        con.commit()\n",
    "    except Exception as e:\n",
    "        \n",
    "        print(str(e))\n",
    "        print(line)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "43f382d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npath = os.path.abspath(\\'\\') \\npath = path+\"\\\\\"+foldataname\\nprint(f\"The Path Dirction :: {path}\\n----------------\\n\\nThe Content Path\\n\")\\nprint(\"=======================Path found done===============================\")\\nprint(\"==========================================================================\")\\n\\ndf = pd.DataFrame()\\nfiles = os.listdir(path)\\nfor file in files:\\n    if file.endswith(\\'.csv\\'):\\n        print(file)\\n        df = df.append(pd.read_csv(f\"{path}\\\\{file}\"), ignore_index=True) \\ndf.head() \\ndf.to_csv(f\\'{path}\\\\{MergeCSVFileNAme}.csv\\' , index = False)\\nprint(\"=======================Read 2 CSV Filies and Merged done============================\")\\nprint(\"==========================================================================\")\\ntbIns = pd.read_csv(f\\'{path}\\\\{MergeCSVFileNAme}.csv\\' )\\n# casting DataTime Tybe\\ntbIns[\\'BARTIMESTAMP\\'] = pd.to_datetime(tbIns[\\'BARTIMESTAMP\\'],  errors=\\'coerce\\')\\n# Set DateTime as Index of DataFrame\\ntbIns.set_index(\"BARTIMESTAMP\" , inplace=True)\\ntbIns.sort_index(ascending = True, inplace=True)\\nprint(\"======================Sorting Data of File done============================\")\\nprint(\"==========================================================================\")\\ntbIns\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "path = os.path.abspath('') \n",
    "path = path+\"\\\\\"+foldataname\n",
    "print(f\"The Path Dirction :: {path}\\n----------------\\n\\nThe Content Path\\n\")\n",
    "print(\"=======================Path found done===============================\")\n",
    "print(\"==========================================================================\")\n",
    "\n",
    "df = pd.DataFrame()\n",
    "files = os.listdir(path)\n",
    "for file in files:\n",
    "    if file.endswith('.csv'):\n",
    "        print(file)\n",
    "        df = df.append(pd.read_csv(f\"{path}\\\\{file}\"), ignore_index=True) \n",
    "df.head() \n",
    "df.to_csv(f'{path}\\\\{MergeCSVFileNAme}.csv' , index = False)\n",
    "print(\"=======================Read 2 CSV Filies and Merged done============================\")\n",
    "print(\"==========================================================================\")\n",
    "tbIns = pd.read_csv(f'{path}\\\\{MergeCSVFileNAme}.csv' )\n",
    "# casting DataTime Tybe\n",
    "tbIns['BARTIMESTAMP'] = pd.to_datetime(tbIns['BARTIMESTAMP'],  errors='coerce')\n",
    "# Set DateTime as Index of DataFrame\n",
    "tbIns.set_index(\"BARTIMESTAMP\" , inplace=True)\n",
    "tbIns.sort_index(ascending = True, inplace=True)\n",
    "print(\"======================Sorting Data of File done============================\")\n",
    "print(\"==========================================================================\")\n",
    "tbIns\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5423113e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncon=dbConnect()\\ncur = con.cursor()\\nlines=[]\\nfor index,row in tbIns.iterrows():\\n    try:\\n        line=[0,1,2,3,4,5,6,7,8]\\n        line[0]=row[\"TICKER\"]\\n        #line[0]=\"ABG\"\\n        line[1]=row[\\'OPEN\\']\\n        line[2]=row[\\'HIGH\\']\\n        line[3]=row[\\'LOW\\']\\n        line[4]=row[\\'CLOSE\\']\\n        line[5]=row[\\'VOLUME\\']\\n        line[6]=index.to_pydatetime()\\n        line[7]=1\\n        line[8]=row[\\'VWAP\\']\\n        #print(index.to_pydatetime())\\n        lines.append(line)\\n\\n        #print(lines)\\n        print(line)\\n        cur.execute(\"insert into FILL_OHLCV(TICKER,OPEN,HIGH,LOW,CLOSE,VOLUME,BARTIMESTAMP,ASSET,VWAP) values (:TICKER, :OPEN,:HIGH,:LOW,:CLOSE,:VOLUME,:BARTIMESTAMP,:1,:2)\",line)\\n        con.commit()\\n    except Exception as e:\\n        \\n        print(str(e))\\n        print(line)\\n        \\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "con=dbConnect()\n",
    "cur = con.cursor()\n",
    "lines=[]\n",
    "for index,row in tbIns.iterrows():\n",
    "    try:\n",
    "        line=[0,1,2,3,4,5,6,7,8]\n",
    "        line[0]=row[\"TICKER\"]\n",
    "        #line[0]=\"ABG\"\n",
    "        line[1]=row['OPEN']\n",
    "        line[2]=row['HIGH']\n",
    "        line[3]=row['LOW']\n",
    "        line[4]=row['CLOSE']\n",
    "        line[5]=row['VOLUME']\n",
    "        line[6]=index.to_pydatetime()\n",
    "        line[7]=1\n",
    "        line[8]=row['VWAP']\n",
    "        #print(index.to_pydatetime())\n",
    "        lines.append(line)\n",
    "\n",
    "        #print(lines)\n",
    "        print(line)\n",
    "        cur.execute(\"insert into FILL_OHLCV(TICKER,OPEN,HIGH,LOW,CLOSE,VOLUME,BARTIMESTAMP,ASSET,VWAP) values (:TICKER, :OPEN,:HIGH,:LOW,:CLOSE,:VOLUME,:BARTIMESTAMP,:1,:2)\",line)\n",
    "        con.commit()\n",
    "    except Exception as e:\n",
    "        \n",
    "        print(str(e))\n",
    "        print(line)\n",
    "        \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "926d196a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntbIns[\"TICKER\"] = tbIns[\"TICKER\"].apply(lambda x : \"GBCO\" if x == \"AUTO\" else \"GBCO\")\\ntbIns = tbIns.drop([\\'Unnamed: 0\\',\\'Unnamed: 0.1\\'], axis=1)\\ntbIns.to_csv(\"Last-Data-Auto-Handle.csv\")\\ntbIns= pd.read_csv(\"Last-Data-Auto-Handle.csv\")\\ntbIns\\ntbIns.columns\\ntbIns[\"TICKER\"] = tbIns[\"TICKER\"].apply(lambda x : \"GBCO\" if x == \"AUTO\" else \"GBCO\")\\ntbIns = tbIns.drop([\\'Unnamed: 0\\',\\'Unnamed: 0.1\\'], axis=1)\\ntbIns.to_csv(\"Last-Data-Auto-Handle.csv\")\\ntbIns= pd.read_csv(\"Last-Data-Auto-Handle.csv\")\\ntbIns\\nFILL_OHLCV_dataFile[FILL_OHLCV_dataFile[\"TICKER\"] ==\"GBCO\"].to_csv(\"GBCOTION.csv\")\\ntbIns = pd.read_csv(\"GBCOTION.csv\")\\ntbIns\\n# read-Csv as DataFrame\\ntbIns = pd.read_csv(\"All-data-ofAuto-after-Handle.csv\")\\n# casting DataTime Tybe\\n#tbIns[\"TICKER\"] = tbIns[\"TICKER\"].apply(lambda x \"ARAB\" if x == \"PORT\" else \"ARAB\")\\ntbIns[\\'BARTIMESTAMP\\'] = pd.to_datetime(tbIns[\\'BARTIMESTAMP\\'],  errors=\\'coerce\\')\\n# Set DateTime as Index of DataFrame\\ntbIns.set_index(\"BARTIMESTAMP\" , inplace=True)\\ntbIns.sort_index(ascending = True, inplace=True)\\nprint(\"Sorting Data VAlues done\")\\ntbIns\\n\\n#tbIns.drop( index=[61617 : ] )\\ncon=dbConnect()\\ncur = con.cursor()\\nlines=[]\\nfor index,row in tbIns.iterrows():\\n    try:\\n        line=[0,1,2,3,4,5,6,7,8]\\n        line[0]=row[\"TICKER\"]\\n        #line[0]=\"ABG\"\\n        line[1]=row[\\'OPEN\\']\\n        line[2]=row[\\'HIGH\\']\\n        line[3]=row[\\'LOW\\']\\n        line[4]=row[\\'CLOSE\\']\\n        line[5]=row[\\'VOLUME\\']\\n        line[6]=index.to_pydatetime()\\n        line[7]=1\\n        line[8]=row[\\'VWAP\\']\\n        #print(index.to_pydatetime())\\n        lines.append(line)\\n\\n        #print(lines)\\n        print(line)\\n        cur.execute(\"insert into FILL_OHLCV(TICKER,OPEN,HIGH,LOW,CLOSE,VOLUME,BARTIMESTAMP,ASSET,VWAP) values (:TICKER, :OPEN,:HIGH,:LOW,:CLOSE,:VOLUME,:BARTIMESTAMP,:1,:2)\",line)\\n        con.commit()\\n    except Exception as e:\\n        \\n        print(str(e))\\n        print(line)\\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "tbIns[\"TICKER\"] = tbIns[\"TICKER\"].apply(lambda x : \"GBCO\" if x == \"AUTO\" else \"GBCO\")\n",
    "tbIns = tbIns.drop(['Unnamed: 0','Unnamed: 0.1'], axis=1)\n",
    "tbIns.to_csv(\"Last-Data-Auto-Handle.csv\")\n",
    "tbIns= pd.read_csv(\"Last-Data-Auto-Handle.csv\")\n",
    "tbIns\n",
    "tbIns.columns\n",
    "tbIns[\"TICKER\"] = tbIns[\"TICKER\"].apply(lambda x : \"GBCO\" if x == \"AUTO\" else \"GBCO\")\n",
    "tbIns = tbIns.drop(['Unnamed: 0','Unnamed: 0.1'], axis=1)\n",
    "tbIns.to_csv(\"Last-Data-Auto-Handle.csv\")\n",
    "tbIns= pd.read_csv(\"Last-Data-Auto-Handle.csv\")\n",
    "tbIns\n",
    "FILL_OHLCV_dataFile[FILL_OHLCV_dataFile[\"TICKER\"] ==\"GBCO\"].to_csv(\"GBCOTION.csv\")\n",
    "tbIns = pd.read_csv(\"GBCOTION.csv\")\n",
    "tbIns\n",
    "# read-Csv as DataFrame\n",
    "tbIns = pd.read_csv(\"All-data-ofAuto-after-Handle.csv\")\n",
    "# casting DataTime Tybe\n",
    "#tbIns[\"TICKER\"] = tbIns[\"TICKER\"].apply(lambda x \"ARAB\" if x == \"PORT\" else \"ARAB\")\n",
    "tbIns['BARTIMESTAMP'] = pd.to_datetime(tbIns['BARTIMESTAMP'],  errors='coerce')\n",
    "# Set DateTime as Index of DataFrame\n",
    "tbIns.set_index(\"BARTIMESTAMP\" , inplace=True)\n",
    "tbIns.sort_index(ascending = True, inplace=True)\n",
    "print(\"Sorting Data VAlues done\")\n",
    "tbIns\n",
    "\n",
    "#tbIns.drop( index=[61617 : ] )\n",
    "con=dbConnect()\n",
    "cur = con.cursor()\n",
    "lines=[]\n",
    "for index,row in tbIns.iterrows():\n",
    "    try:\n",
    "        line=[0,1,2,3,4,5,6,7,8]\n",
    "        line[0]=row[\"TICKER\"]\n",
    "        #line[0]=\"ABG\"\n",
    "        line[1]=row['OPEN']\n",
    "        line[2]=row['HIGH']\n",
    "        line[3]=row['LOW']\n",
    "        line[4]=row['CLOSE']\n",
    "        line[5]=row['VOLUME']\n",
    "        line[6]=index.to_pydatetime()\n",
    "        line[7]=1\n",
    "        line[8]=row['VWAP']\n",
    "        #print(index.to_pydatetime())\n",
    "        lines.append(line)\n",
    "\n",
    "        #print(lines)\n",
    "        print(line)\n",
    "        cur.execute(\"insert into FILL_OHLCV(TICKER,OPEN,HIGH,LOW,CLOSE,VOLUME,BARTIMESTAMP,ASSET,VWAP) values (:TICKER, :OPEN,:HIGH,:LOW,:CLOSE,:VOLUME,:BARTIMESTAMP,:1,:2)\",line)\n",
    "        con.commit()\n",
    "    except Exception as e:\n",
    "        \n",
    "        print(str(e))\n",
    "        print(line)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d8ee37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297703fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32a8b47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482d6fbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0880fd8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3315c07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7e9a69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27a474e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75789c2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174a5db0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
